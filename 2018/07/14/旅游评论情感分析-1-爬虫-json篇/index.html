<!DOCTYPE html><html lang="zh-Hans"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="旅游评论情感分析(1)---爬虫(json篇)"><meta name="keywords" content="旅游评论情感分析,爬虫"><meta name="author" content="Pluking"><meta name="copyright" content="Pluking"><title>旅游评论情感分析(1)---爬虫(json篇) | 考不上PKU不改名</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.5.6"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.5.6"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
} </script></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/avatar.png"></div><div class="author-info__name text-center">Pluking</div><div class="author-info__description text-center">勿忘初心</div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">5</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">4</span></a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://wx1.sinaimg.cn/large/006AzjaPgy1g063q5upmcj31900u0b2b.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">考不上PKU不改名</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page" href="/">主页</a><a class="site-page" href="/archives">博文</a><a class="site-page" href="/tags">标签</a><a class="site-page" href="/categories">其他</a></span></div><div id="post-info"><div id="post-title">旅游评论情感分析(1)---爬虫(json篇)</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-07-14</time></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><p><em>从今天开始准备整理一下，之前的写过的一些小项目。</em></p>
<p><em>这一个项目是我唯一一个接触NLP的项目，因为身边的老师大多是从事CV 机器视觉一块的项目。<br>而对于我而言，NLP其实是我学习机器学习的初衷。</em></p>
<p><em>因为，暑假实训的关系认识了一个妹子是学习旅游专业，他们需要对我国某一个地方的旅游景点需要进行考察，除了他们之后实地考察外，我们小组的实训任务是帮助他们在网上下载阳朔的旅游景点的评论。并加以分析情感。</em></p>
<hr>
<p>所以关于这一个项目，我们第一个要做的就是获取数据。<br>这是作为机器学习的根本。没有数据根本就谈不上学习。</p>
<p>前言—选择网站进行数据挖掘</p>
<p> 这次实训我们一共获取了飞猪， 途牛， 驴妈妈， 美团， 携程， 去哪儿， 马蜂窝，猫途鹰等相关网站的关于阳朔旅游景点的评论。</p>
<p>这其中比较复杂的是大众点评，因为cookie限制非常严。我和另一个同学一人选择一半进行爬取数据。</p>
<p>以下我用去哪儿的网站爬虫为例。</p>
<ol>
<li>获取网页链接<br><img src="https://wx1.sinaimg.cn/large/006AzjaPgy1g060txkzygj31vm0ie48a.jpg" alt="调研结果"><br>这是我们事先做好阳朔在去哪儿网的网站调查。</li>
</ol>
<p>我们发现其实去哪儿的数据是一个开发的平台，并且我不需要翻阅每一个网站，我只需要找到他每一页的json页面直接获取，十分的方便。</p>
<p>具体是怎么发现内含json直接传值，我们就必须先打开web控制台。<br><img src="https://wx3.sinaimg.cn/large/006AzjaPgy1g0617c9cx5j31v00cywk2.jpg" alt="怎么获取json网站"></p>
<p>我用的firefox浏览器，打开网选项，并且在网络中只看XHR。</p>
<p>这时候，我们再通过点击下一页评论就可以找到json的相关网站。</p>
<p>通过对比json网站，我们发现 他的网站格式都是遵守着”<a href="http://piao.qunar.com/ticket/detailLight/sightCommentList.json?sightId=&quot;" target="_blank" rel="noopener">http://piao.qunar.com/ticket/detailLight/sightCommentList.json?sightId=&quot;</a> + 景点编号+ “&amp;index=” + 景点编号+ “&amp;page=” + page编号 + “&amp;pageSize=10&amp;tagType=0”</p>
<p>  所以我们就通过遍历excel文件，遍历每一个我们需要爬虫的每一个网站。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">file = pd.read_excel(r&quot;Excel路径&quot;)</span><br><span class="line">name = file[&apos;name&apos;]         #获取word上面景区名字</span><br><span class="line">#pagenums = file[&apos;page&apos;]     #获取总共页数</span><br><span class="line">for city in range(len(file[&apos;name&apos;])):</span><br><span class="line">	weburl = file[&apos;url&apos;]  # 网站url</span><br><span class="line">    webnum = file[&apos;id&apos;]  # 网站id</span><br><span class="line">    </span><br><span class="line">    url = r&quot;http://piao.qunar.com/ticket/detailLight/sightCommentList.json?sightId=&quot; + str(</span><br><span class="line">        webnum[num]) + &quot;&amp;index=&quot; + str(pagenum) \</span><br><span class="line">          + &quot;&amp;page=&quot; + str(pagenum) + &quot;&amp;pageSize=10&amp;tagType=0&quot;</span><br></pre></td></tr></table></figure>
<ol start="2">
<li><p>查看网页布局</p>
<p><img src="https://wx1.sinaimg.cn/large/006AzjaPgy1g061d4nl9uj31nb0u0n5q.jpg" alt="json在网页上的格式"><br>由我们发现网站很明显的数据格式，一下让问题变得很简单了。我们现在需要做的时候是利用python 进行json数据的获取。</p>
</li>
</ol>
<p>在此之前我们需要在获取json数据前，伪装一下自己的身份，给自己加上cookie，使得爬虫这一行为更像是人在点击获取数据。</p>
<p>下拉上述图片所示的消息头得到本电脑的cookie等相关数据。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">headers = &#123;</span><br><span class="line">        &apos;Cookie&apos;: &apos;自己或其他人的信息&apos;,</span><br><span class="line">        &apos;User-Agent&apos;: &apos; 相关信息&apos;,</span><br><span class="line">        &apos;Referer&apos;: weburl[num]&#125;</span><br><span class="line"></span><br><span class="line">    #判断网络情况情况</span><br><span class="line">    flag = True</span><br><span class="line">    df = pd.DataFrame()</span><br><span class="line">    requests.adapters.DEFAULT_RETRIES = 5</span><br><span class="line">    try:</span><br><span class="line">        response = requests.get(url, headers=headers)</span><br><span class="line">    except ConnectionError:</span><br><span class="line">        return df, flag</span><br><span class="line">        pass</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>利用python实现在json中获取信息</li>
</ol>
<p>我们需要的数据分别是评论，分数和日期。所以我们分别建立三个数组<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">if (response.status_code == 200):</span><br><span class="line">      html = response.text   #将html转化为text</span><br><span class="line">      html.encode(&quot;utf-8&quot;)   #转化为UTF-8格式</span><br><span class="line">      jsontest = json.loads(html) #将文本格式转化为json</span><br><span class="line">      </span><br><span class="line">      #然后根据网页显示的json格式获取到所需要的信息</span><br><span class="line">      judge = jsonpath(jsontest, &quot;$..author&quot;)</span><br><span class="line">      if (type(judge) == bool):</span><br><span class="line">          flag = False</span><br><span class="line">      #建立 评论 分数， 时间，三个我们需要获取的指标</span><br><span class="line">      </span><br><span class="line">  comment = []</span><br><span class="line">  score = []</span><br><span class="line">  date = []</span><br><span class="line">  </span><br><span class="line">  try:</span><br><span class="line">          # for x in jsonpath(jsontest,&quot;$..userId&quot;):</span><br><span class="line">          # userId.append(x)</span><br><span class="line">          # for x in jsonpath(jsontest,&quot;$..comment&quot;):</span><br><span class="line">          # comment.append(x)</span><br><span class="line">          for x in jsonpath(jsontest, &quot;$..date&quot;):</span><br><span class="line">              date.append(x)</span><br><span class="line">          for x in jsonpath(jsontest, &quot;$..score&quot;):</span><br><span class="line">              score.append(x)</span><br><span class="line">          for x in jsonpath(jsontest, &quot;$..content&quot;):</span><br><span class="line">              comment.append(x)</span><br><span class="line">      except TypeError:</span><br><span class="line">          pass</span><br></pre></td></tr></table></figure></p>
<p><img src="https://wx2.sinaimg.cn/large/006AzjaPgy1g062yqomtfj314k0ri7hx.jpg" alt="爬虫数据"></p>
<p>最后将三个数组整合成一个dataframe,并且输出我们所得到的数据，便完成了一个网站的爬虫工作。</p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Pluking</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://pluto1997.github.io/2018/07/14/旅游评论情感分析-1-爬虫-json篇/">https://pluto1997.github.io/2018/07/14/旅游评论情感分析-1-爬虫-json篇/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://pluto1997.github.io">考不上PKU不改名</a>！</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/旅游评论情感分析/">旅游评论情感分析</a><a class="post-meta__tags" href="/tags/爬虫/">爬虫</a></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2018/07/14/旅游评论情感分析-1-爬虫-xpath-re补充篇/"><i class="fa fa-chevron-left">  </i><span> 旅游评论情感分析(1)---爬虫(xpath re补充篇)</span></a></div><div class="next-post pull-right"><a href="/2018/02/15/旅游评论情感分析-2-前期调查总结/"><span>旅游评论情感分析(2)---前期调查总结</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2019 By Pluking</div><div class="framework-info"><span>驱动 - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.5.6"></script><script src="/js/fancybox.js?version=1.5.6"></script><script src="/js/sidebar.js?version=1.5.6"></script><script src="/js/copy.js?version=1.5.6"></script><script src="/js/fireworks.js?version=1.5.6"></script><script src="/js/transition.js?version=1.5.6"></script><script src="/js/scroll.js?version=1.5.6"></script><script src="/js/head.js?version=1.5.6"></script></body></html>